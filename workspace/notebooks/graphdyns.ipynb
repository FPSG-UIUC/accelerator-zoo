{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf014ca-328b-4b00-9e97-1f5ff73e8b40",
   "metadata": {},
   "source": [
    "# GraphDynS\n",
    "\n",
    "This notebook reproduces the salient characteristics of the [GraphDynS](https://dl.acm.org/doi/10.1145/3352460.3358318) accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6abc4-468f-4815-9838-5d75a1065e60",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117402a4-e1f4-4e69-aa91-47830631731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFiber boilerplate\n",
    "\n",
    "from fibertree_bootstrap import *\n",
    "\n",
    "fibertree_bootstrap(style=\"tree\", animation='movie')\n",
    "\n",
    "# Compilation boilerplate\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a49aa-326e-43e8-bdec-f842bb137821",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Initialize the input tensors. Tensor shapes and densities can be modified below. For BFS, use `interval=1`, for SSSP use an `interval=10` when constructing `G_SD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd88e28-c190-4ffe-9d63-af3dd1bc5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 15\n",
    "\n",
    "density = [1, 0.3]\n",
    "seed = 0\n",
    "\n",
    "N = 12\n",
    "n = 2\n",
    "m = 2\n",
    "mask_shape = N // 2\n",
    "\n",
    "G_SD = Tensor.fromRandom(rank_ids=[\"S\", \"D\"], shape=[V, V], seed=seed, density=density, interval=1, name=\"G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5d0c3-68c6-4f7b-a9fe-dc2ed0e65311",
   "metadata": {},
   "source": [
    "Visualize the initial graph's adjacency matrix. Skip this step if the graph is large (more than 70 edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187737a-8a80-449e-85cc-b78d4b287102",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(G_SD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ec5d4-c844-4a9d-8154-d0859f93f504",
   "metadata": {},
   "source": [
    "## Running GraphDynS with TeAAL/HiFiber\n",
    "\n",
    "The TeAAL compiler currently only supports basic tensor algebra operations. Specifically, it has three restrictions:\n",
    "- The **map** operator can only be either multiplication (`*`) or addition (`+`)\n",
    "- The **reduce** operator can only be addition (`+`)\n",
    "- The **default** for all outputs can only be `0`\n",
    "\n",
    "However, graph algorithms require much more variety across all attributes. Therefore, in this notebook, we present a TeAAL specification that *must* be modified to accurately perform breadth-first search (BFS) or single-source shortest path (SSSP).\n",
    "\n",
    "In this notebook, we do not differentiate between compressed and uncompressed iteration (all iteration is compressed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c8155-9317-45e5-853a-2daa1c8f342a",
   "metadata": {},
   "source": [
    "### GraphDynS TeAAL Specification\n",
    "\n",
    "For BFS/SSSP, the property we are trying to assign each vertex is its distance away from the start vertex. For a single iteration of the BFS/SSSP algorithm, we have the following tensors:\n",
    "- `G`: Graph\n",
    "- `A0`: Set of active vertices at the start of this iteration (initial frontier)\n",
    "- `SO`: Graph edges whose sources are in `A0`\n",
    "- `R`: Potential update to the vertex properties\n",
    "- `MP`: Set of vertices that were updated on this iteration, paired with their initial property value\n",
    "- `NP`: Set of vertices to be updated with the best property value\n",
    "- `P0`: Set of vertex properties at the start of the iteration\n",
    "- `P1`: Updated set of vertex properties\n",
    "- `M`: Set of vertices that were actually updated on this iteration\n",
    "- `A1`: Set of active vertices at the end of this iteration (updated frontier)\n",
    "\n",
    "The TeAAL specification for GraphDynS is:\n",
    "```yaml\n",
    "einsum:\n",
    "    declaration:\n",
    "        G: [D, S]\n",
    "        A0: [S]\n",
    "        SO: [D, S]\n",
    "        R: [V]\n",
    "        MP: [V]\n",
    "        NP: [V]\n",
    "        P0: [V]\n",
    "        P1: [V]\n",
    "        M: [V]\n",
    "        A1: [V]\n",
    "    expressions:\n",
    "        - SO[d, s] = take(G[d, s], A0[s], 0)\n",
    "        - R[d] = SO[d, s] * A0[s]\n",
    "        - MP[v] = take(R[v], P0[v], 1)\n",
    "        - NP[v] = R[v] + MP[v]\n",
    "        - M[v] = MP[v] + s * NP[v]\n",
    "        - P1[v] = take(M[v], NP[v], 1)\n",
    "        - A1[v] = take(M[v], NP[v], 1)\n",
    "mapping:\n",
    "    rank-order:\n",
    "        G: [S, D]\n",
    "    partitioning:\n",
    "        SO:\n",
    "            D: [uniform_shape(N), uniform_shape(mask_shape)]\n",
    "            S: [uniform_shape(N), uniform_shape(m)]\n",
    "        R:\n",
    "            D: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "            S: [uniform_shape(N)]\n",
    "            V: [follow(D)]\n",
    "        MP:\n",
    "            V: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "        NP:\n",
    "            V: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "        M:\n",
    "            V: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "        P1:\n",
    "            V: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "        A1:\n",
    "            V: [uniform_shape(N), uniform_shape(mask_shape), uniform_shape(n)]\n",
    "    loop-order:\n",
    "        SO: [D2, S2, S1, S0, D1, D0]\n",
    "        R: [V3, S1, S0, V2, V1, V0]\n",
    "        MP: [V3, V2, V1, V0]\n",
    "        NP: [V3, V2, V1, V0]\n",
    "        M: [V3, V2, V1, V0]\n",
    "        P1: [V3, V2, V1, V0]\n",
    "        A1: [V3, V2, V1, V0]\n",
    "    spacetime:\n",
    "        SO:\n",
    "            space: [S0.coord]\n",
    "            time: [D1, S2, S1, D0]\n",
    "            opt: slip\n",
    "        R:\n",
    "            space: [D0.coord]\n",
    "            time: [D2, S1, S0, D1]\n",
    "            opt: slip\n",
    "        MP:\n",
    "            space: [V0.coord]\n",
    "            time: [V3, V2, V1]\n",
    "            opt: slip\n",
    "        NP:\n",
    "            space: [V0.coord]\n",
    "            time: [V3, V2, V1]\n",
    "            opt: slip\n",
    "        M:\n",
    "            space: [V0.coord]\n",
    "            time: [V3, V2, V1]\n",
    "            opt: slip\n",
    "        P1:\n",
    "            space: [V0.coord]\n",
    "            time: [V3, V2, V1]\n",
    "            opt: slip\n",
    "        A1:\n",
    "            space: [V0.coord]\n",
    "            time: [V3, V2, V1]\n",
    "            opt: slip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dea45-b9b6-42a8-a732-0045794523c8",
   "metadata": {},
   "source": [
    "### Per-Run Initialization\n",
    "\n",
    "Create the tensor of active vertices and the tensor of property values. The `start_vertex` can be modified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7842386-bc3c-4db4-ac17-bdd5a294a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vertex = 0\n",
    "\n",
    "A0_S = Tensor.fromFiber(rank_ids=[\"S\"], fiber=Fiber([start_vertex], [0]), default=float(\"inf\"), name=\"A0\")\n",
    "P0_V = Tensor.fromFiber(rank_ids=[\"V\"], fiber=Fiber([start_vertex], [0], default=float(\"inf\")), default=float(\"inf\"), name=\"P0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b67833-d727-4b3e-b6bb-fde5f2331674",
   "metadata": {},
   "source": [
    "### Modified HiFiber Ouput\n",
    "\n",
    "Below is the HiFiber output obtained by compiling the above TeAAL specification (minus the `spacetime` stamp). It has been modified to actually perform BFS/SSSP.\n",
    "\n",
    "In general, the changes are as follows:\n",
    "- Multiplication (`*`) is remapped to addition (`+`)\n",
    "- Addition (`+`) is remapped to minimum (`min`)\n",
    "- Subtraction (`-` or `+ s *`) is remapped to not equal (`!=`)\n",
    "\n",
    "To match this change, the default values for the following tensors need to be manually updated:\n",
    "- `R`: `float(\"inf\")`\n",
    "- `M`: `False`\n",
    "- `A1`: `float(\"inf\")`\n",
    "\n",
    "Additionally, Einsum notation is static single assigment (SSA), but the vector of properties is *updated* from iteration to iteration. So, instead of creating a new tensor `P1`, we must copy `P0` into `P1`.\n",
    "\n",
    "Finally, we add a loop, which continues as long as there are active vertices.\n",
    "\n",
    "The inline comments describe the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e9132-c5ef-4b9e-a93a-016971e3fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TeAAL specification is for a single iteration, to perform the full BFS/SSSP, loop until the set of active vertices is empty\n",
    "while len(A0_S.getRoot()) > 0:\n",
    "\n",
    "    # Track progress by displaying vertex distance seen so far\n",
    "    P0_V.setName(\"P\")\n",
    "    displayTensor(P0_V)\n",
    "\n",
    "    # Modified HiFiber\n",
    "    SO_D2S2S1S0D1D0 = Tensor(rank_ids=[\"D2\", \"S2\", \"S1\", \"S0\", \"D1\", \"D0\"], name=\"SO\")\n",
    "    tmp0 = G_SD\n",
    "    tmp1 = tmp0.splitUniform(N, depth=1)\n",
    "    tmp2 = tmp1.splitUniform(mask_shape, depth=2)\n",
    "    G_SD2D1D0 = tmp2\n",
    "    G_SD2D1D0.setRankIds(rank_ids=[\"S\", \"D2\", \"D1\", \"D0\"])\n",
    "    tmp3 = G_SD2D1D0\n",
    "    tmp4 = tmp3.splitUniform(N, depth=0)\n",
    "    tmp5 = tmp4.splitUniform(m, depth=1)\n",
    "    G_S2S1S0D2D1D0 = tmp5\n",
    "    G_S2S1S0D2D1D0.setRankIds(rank_ids=[\"S2\", \"S1\", \"S0\", \"D2\", \"D1\", \"D0\"])\n",
    "    tmp6 = A0_S\n",
    "    tmp7 = tmp6.splitUniform(N, depth=0)\n",
    "    tmp8 = tmp7.splitUniform(m, depth=1)\n",
    "    A0_S2S1S0 = tmp8\n",
    "    A0_S2S1S0.setRankIds(rank_ids=[\"S2\", \"S1\", \"S0\"])\n",
    "    so_d2 = SO_D2S2S1S0D1D0.getRoot()\n",
    "    G_D2S2S1S0D1D0 = G_S2S1S0D2D1D0.swizzleRanks(rank_ids=[\"D2\", \"S2\", \"S1\", \"S0\", \"D1\", \"D0\"])\n",
    "    g_d2 = G_D2S2S1S0D1D0.getRoot()\n",
    "    a0_s2 = A0_S2S1S0.getRoot()\n",
    "    for d2, (so_s2, g_s2) in so_d2 << g_d2:\n",
    "        for s2, (so_s1, (g_s1, a0_s1)) in so_s2 << (g_s2 & a0_s2):\n",
    "            for s1, (so_s0, (g_s0, a0_s0)) in so_s1 << (g_s1 & a0_s1):\n",
    "                for s0, (so_d1, (g_d1, a0_val)) in so_s0 << (g_s0 & a0_s0):\n",
    "                    for d1, (so_d0, g_d0) in so_d1 << g_d1:\n",
    "                        for d0, (so_ref, g_val) in so_d0 << g_d0:\n",
    "                            so_ref <<= g_val\n",
    "    tmp9 = SO_D2S2S1S0D1D0\n",
    "    tmp10 = tmp9.swizzleRanks(rank_ids=[\"D2\", \"D1\", \"D0\", \"S2\", \"S1\", \"S0\"])\n",
    "    tmp11 = tmp10.mergeRanks(depth=3, levels=2, coord_style=\"absolute\")\n",
    "    tmp12 = tmp11.mergeRanks(depth=0, levels=2, coord_style=\"absolute\")\n",
    "    tmp12.setRankIds(rank_ids=[\"D\", \"S\"])\n",
    "    SO_DS = tmp12\n",
    "    # Custom default\n",
    "    R_V3V2V1V0 = Tensor(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"], default=float(\"inf\"), name=\"R\")\n",
    "    tmp13 = SO_DS\n",
    "    tmp14 = tmp13.splitUniform(N, depth=0)\n",
    "    tmp15 = tmp14.splitUniform(mask_shape, depth=1)\n",
    "    tmp16 = tmp15.splitUniform(n, depth=2)\n",
    "    SO_D3D2D1D0S = tmp16\n",
    "    SO_D3D2D1D0S.setRankIds(rank_ids=[\"D3\", \"D2\", \"D1\", \"D0\", \"S\"])\n",
    "    tmp17 = SO_D3D2D1D0S\n",
    "    tmp18 = tmp17.splitUniform(N, depth=4)\n",
    "    SO_D3D2D1D0S1S0 = tmp18\n",
    "    SO_D3D2D1D0S1S0.setRankIds(rank_ids=[\"D3\", \"D2\", \"D1\", \"D0\", \"S1\", \"S0\"])\n",
    "    tmp19 = A0_S\n",
    "    tmp20 = tmp19.splitUniform(N, depth=0)\n",
    "    A0_S1S0 = tmp20\n",
    "    A0_S1S0.setRankIds(rank_ids=[\"S1\", \"S0\"])\n",
    "    r_v3 = R_V3V2V1V0.getRoot()\n",
    "    SO_D3S1S0D2D1D0 = SO_D3D2D1D0S1S0.swizzleRanks(rank_ids=[\"D3\", \"S1\", \"S0\", \"D2\", \"D1\", \"D0\"])\n",
    "    so_d3 = SO_D3S1S0D2D1D0.getRoot()\n",
    "    a0_s1 = A0_S1S0.getRoot()\n",
    "    for v3, (r_v2, so_s1) in r_v3 << so_d3.project(trans_fn=lambda d3: d3):\n",
    "        for s1, (so_s0, a0_s0) in so_s1 & a0_s1:\n",
    "            for s0, (so_d2, a0_val) in so_s0 & a0_s0:\n",
    "                for v2, (r_v1, so_d1) in r_v2 << so_d2.project(trans_fn=lambda d2: d2):\n",
    "                    inputs_v1 = Fiber.fromLazy(so_d1.project(trans_fn=lambda d1: d1))\n",
    "                    for v1_pos, (v1, (r_v0, so_d0)) in enumerate(r_v1 << so_d1.project(trans_fn=lambda d1: d1)):\n",
    "                        if v1_pos == 0:\n",
    "                            v0_start = 0\n",
    "                        else:\n",
    "                            v0_start = v1\n",
    "                        if v1_pos + 1 < len(inputs_v1):\n",
    "                            v0_end = inputs_v1.getCoords()[v1_pos + 1]\n",
    "                        else:\n",
    "                            v0_end = V\n",
    "                        for v0, (r_ref, so_val) in r_v0 << so_d0.project(trans_fn=lambda d0: d0, interval=(v0_start, v0_end)):\n",
    "                            # + => min, * => +\n",
    "                            r_ref <<= min(r_ref, so_val + a0_val)\n",
    "    tmp21 = R_V3V2V1V0\n",
    "    tmp22 = tmp21.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp22.setRankIds(rank_ids=[\"V\"])\n",
    "    R_V = tmp22\n",
    "    # Custom default\n",
    "    # Explicit shape to deal with the fact that sometimes MP is empty\n",
    "    MP_V3V2V1V0 = Tensor(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"], default=float(\"inf\"), name=\"MP\", shape=[V, V, V, V])\n",
    "    tmp23 = R_V\n",
    "    tmp24 = tmp23.splitUniform(N, depth=0)\n",
    "    tmp25 = tmp24.splitUniform(mask_shape, depth=1)\n",
    "    tmp26 = tmp25.splitUniform(n, depth=2)\n",
    "    R_V3V2V1V0 = tmp26\n",
    "    R_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    tmp27 = P0_V\n",
    "    tmp28 = tmp27.splitUniform(N, depth=0)\n",
    "    tmp29 = tmp28.splitUniform(mask_shape, depth=1)\n",
    "    tmp30 = tmp29.splitUniform(n, depth=2)\n",
    "    P0_V3V2V1V0 = tmp30\n",
    "    P0_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    mp_v3 = MP_V3V2V1V0.getRoot()\n",
    "    r_v3 = R_V3V2V1V0.getRoot()\n",
    "    p0_v3 = P0_V3V2V1V0.getRoot()\n",
    "    for v3, (mp_v2, (r_v2, p0_v2)) in mp_v3 << (r_v3 & p0_v3):\n",
    "        for v2, (mp_v1, (r_v1, p0_v1)) in mp_v2 << (r_v2 & p0_v2):\n",
    "            for v1, (mp_v0, (r_v0, p0_v0)) in mp_v1 << (r_v1 & p0_v1):\n",
    "                for v0, (mp_ref, (r_val, p0_val)) in mp_v0 << (r_v0 & p0_v0):\n",
    "                    mp_ref <<= p0_val\n",
    "    tmp31 = MP_V3V2V1V0\n",
    "    tmp32 = tmp31.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp32.setRankIds(rank_ids=[\"V\"])\n",
    "    MP_V = tmp32\n",
    "    # Custom default\n",
    "    NP_V3V2V1V0 = Tensor(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"], default=float(\"inf\"), name=\"NP\")\n",
    "    tmp33 = R_V\n",
    "    tmp34 = tmp33.splitUniform(N, depth=0)\n",
    "    tmp35 = tmp34.splitUniform(mask_shape, depth=1)\n",
    "    tmp36 = tmp35.splitUniform(n, depth=2)\n",
    "    R_V3V2V1V0 = tmp36\n",
    "    R_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    tmp37 = MP_V\n",
    "    tmp38 = tmp37.splitUniform(N, depth=0)\n",
    "    tmp39 = tmp38.splitUniform(mask_shape, depth=1)\n",
    "    tmp40 = tmp39.splitUniform(n, depth=2)\n",
    "    MP_V3V2V1V0 = tmp40\n",
    "    MP_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    np_v3 = NP_V3V2V1V0.getRoot()\n",
    "    r_v3 = R_V3V2V1V0.getRoot()\n",
    "    mp_v3 = MP_V3V2V1V0.getRoot()\n",
    "    for v3, (np_v2, (_, r_v2, mp_v2)) in np_v3 << (r_v3 | mp_v3):\n",
    "        for v2, (np_v1, (_, r_v1, mp_v1)) in np_v2 << (r_v2 | mp_v2):\n",
    "            for v1, (np_v0, (_, r_v0, mp_v0)) in np_v1 << (r_v1 | mp_v1):\n",
    "                for v0, (np_ref, (_, r_val, mp_val)) in np_v0 << (r_v0 | mp_v0):\n",
    "                    # + => min\n",
    "                    np_ref <<= min(r_val, mp_val)\n",
    "    tmp41 = NP_V3V2V1V0\n",
    "    tmp42 = tmp41.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp42.setRankIds(rank_ids=[\"V\"])\n",
    "    NP_V = tmp42\n",
    "    # Custom default\n",
    "    M_V3V2V1V0 = Tensor(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"], default=False, name=\"M\")\n",
    "    tmp43 = MP_V\n",
    "    tmp44 = tmp43.splitUniform(N, depth=0)\n",
    "    tmp45 = tmp44.splitUniform(mask_shape, depth=1)\n",
    "    tmp46 = tmp45.splitUniform(n, depth=2)\n",
    "    MP_V3V2V1V0 = tmp46\n",
    "    MP_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    tmp47 = NP_V\n",
    "    tmp48 = tmp47.splitUniform(N, depth=0)\n",
    "    tmp49 = tmp48.splitUniform(mask_shape, depth=1)\n",
    "    tmp50 = tmp49.splitUniform(n, depth=2)\n",
    "    NP_V3V2V1V0 = tmp50\n",
    "    NP_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    m_v3 = M_V3V2V1V0.getRoot()\n",
    "    mp_v3 = MP_V3V2V1V0.getRoot()\n",
    "    np_v3 = NP_V3V2V1V0.getRoot()\n",
    "    for v3, (m_v2, (_, mp_v2, np_v2)) in m_v3 << (mp_v3 | np_v3):\n",
    "        for v2, (m_v1, (_, mp_v1, np_v1)) in m_v2 << (mp_v2 | np_v2):\n",
    "            for v1, (m_v0, (_, mp_v0, np_v0)) in m_v1 << (mp_v1 | np_v1):\n",
    "                for v0, (m_ref, (_, mp_val, np_val)) in m_v0 << (mp_v0 | np_v0):\n",
    "                    # - => !=\n",
    "                    m_ref <<= mp_val != np_val\n",
    "    tmp51 = M_V3V2V1V0\n",
    "    tmp52 = tmp51.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp52.setRankIds(rank_ids=[\"V\"])\n",
    "    M_V = tmp52\n",
    "    # P0 and P1 are actually the same tensor\n",
    "    P1_V3V2V1V0 = deepcopy(P0_V3V2V1V0)\n",
    "    tmp53 = M_V\n",
    "    tmp54 = tmp53.splitUniform(N, depth=0)\n",
    "    tmp55 = tmp54.splitUniform(mask_shape, depth=1)\n",
    "    tmp56 = tmp55.splitUniform(n, depth=2)\n",
    "    M_V3V2V1V0 = tmp56\n",
    "    M_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    tmp57 = NP_V\n",
    "    tmp58 = tmp57.splitUniform(N, depth=0)\n",
    "    tmp59 = tmp58.splitUniform(mask_shape, depth=1)\n",
    "    tmp60 = tmp59.splitUniform(n, depth=2)\n",
    "    NP_V3V2V1V0 = tmp60\n",
    "    NP_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    p1_v3 = P1_V3V2V1V0.getRoot()\n",
    "    m_v3 = M_V3V2V1V0.getRoot()\n",
    "    np_v3 = NP_V3V2V1V0.getRoot()\n",
    "    for v3, (p1_v2, (m_v2, np_v2)) in p1_v3 << (m_v3 & np_v3):\n",
    "        for v2, (p1_v1, (m_v1, np_v1)) in p1_v2 << (m_v2 & np_v2):\n",
    "            for v1, (p1_v0, (m_v0, np_v0)) in p1_v1 << (m_v1 & np_v1):\n",
    "                for v0, (p1_ref, (m_val, np_val)) in p1_v0 << (m_v0 & np_v0):\n",
    "                    p1_ref <<= np_val\n",
    "    tmp61 = P1_V3V2V1V0\n",
    "    tmp62 = tmp61.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp62.setRankIds(rank_ids=[\"V\"])\n",
    "    P1_V = tmp62\n",
    "    # Custom default\n",
    "    A1_V3V2V1V0 = Tensor(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"], default=float(\"inf\"), name=\"A1\")\n",
    "    tmp63 = M_V\n",
    "    tmp64 = tmp63.splitUniform(N, depth=0)\n",
    "    tmp65 = tmp64.splitUniform(mask_shape, depth=1)\n",
    "    tmp66 = tmp65.splitUniform(n, depth=2)\n",
    "    M_V3V2V1V0 = tmp66\n",
    "    M_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    tmp67 = NP_V\n",
    "    tmp68 = tmp67.splitUniform(N, depth=0)\n",
    "    tmp69 = tmp68.splitUniform(mask_shape, depth=1)\n",
    "    tmp70 = tmp69.splitUniform(n, depth=2)\n",
    "    NP_V3V2V1V0 = tmp70\n",
    "    NP_V3V2V1V0.setRankIds(rank_ids=[\"V3\", \"V2\", \"V1\", \"V0\"])\n",
    "    a1_v3 = A1_V3V2V1V0.getRoot()\n",
    "    m_v3 = M_V3V2V1V0.getRoot()\n",
    "    np_v3 = NP_V3V2V1V0.getRoot()\n",
    "    for v3, (a1_v2, (m_v2, np_v2)) in a1_v3 << (m_v3 & np_v3):\n",
    "        for v2, (a1_v1, (m_v1, np_v1)) in a1_v2 << (m_v2 & np_v2):\n",
    "            for v1, (a1_v0, (m_v0, np_v0)) in a1_v1 << (m_v1 & np_v1):\n",
    "                for v0, (a1_ref, (m_val, np_val)) in a1_v0 << (m_v0 & np_v0):\n",
    "                    a1_ref <<= np_val\n",
    "    tmp71 = A1_V3V2V1V0\n",
    "    tmp72 = tmp71.mergeRanks(depth=0, levels=3, coord_style=\"absolute\")\n",
    "    tmp72.setRankIds(rank_ids=[\"V\"])\n",
    "    A1_V = tmp72\n",
    "    \n",
    "    # Prepare for the next iteration\n",
    "    P0_V = P1_V\n",
    "    A0_S = A1_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b68a68-8278-4df6-85a6-f297829c58ab",
   "metadata": {},
   "source": [
    "### Check Results\n",
    "\n",
    "Check that generated code computes the correct result.\n",
    "\n",
    "**Note**: Should be used after running the kernel (above cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e0a8a-1b88-4c44-9354-5d803f15ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.check_bfs_sssp(G_SD, start_vertex, P1_V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
